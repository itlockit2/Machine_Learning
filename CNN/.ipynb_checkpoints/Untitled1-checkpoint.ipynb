{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/banana/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터와 테스트 데이터의 정보가 담겨 있는 csv파일의 위치를 저\n",
    "TRAINING_FILE = '/home/banana/Machine_Learning/CNN/training_file.csv'\n",
    "TEST_FILE = '/home/banana/Machine_Learning/CNN/test_file.csv'\n",
    "\n",
    "def get_input_queue(csv_file_name,num_epochs = None):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for line in open(csv_file_name,'r'):\n",
    "        cols = re.split(',|\\n',line)\n",
    "        train_images.append(cols[0])\n",
    "        # 3rd column is label and needs to be converted to int type\n",
    "        train_labels.append(int(cols[1]))\n",
    "                            \n",
    "    input_queue = tf.train.slice_input_producer([train_images,train_labels],\n",
    "                                               num_epochs = num_epochs,shuffle = True)\n",
    "    \n",
    "    return input_queue\n",
    "\n",
    "def read_data(input_queue):\n",
    "    image_file = input_queue[0]\n",
    "    label = input_queue[1]\n",
    "    \n",
    "    image =  tf.image.decode_jpeg(tf.read_file(image_file),channels=3)\n",
    "    \n",
    "    return image,label,image_file\n",
    "\n",
    "def read_data_batch(csv_file_name,batch_size=100):\n",
    "    input_queue = get_input_queue(csv_file_name)\n",
    "    image,label,file_name= read_data(input_queue)\n",
    "    image = tf.reshape(image,[96,96,3])\n",
    "    \n",
    "    # random image\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image,max_delta=0.5)\n",
    "    image = tf.image.random_contrast(image,lower=0.2,upper=2.0)\n",
    "    image = tf.image.random_hue(image,max_delta=0.08)\n",
    "    image = tf.image.random_saturation(image,lower=0.2,upper=2.0)\n",
    "    \n",
    "    batch_image,batch_label,batch_file = tf.train.batch([image,label,file_name],batch_size=batch_size)\n",
    "    #,enqueue_many=True)\n",
    "    batch_file = tf.reshape(batch_file,[batch_size,1])\n",
    "\n",
    "    batch_label_on_hot=tf.one_hot(tf.to_int64(batch_label),500, on_value=1.0, off_value=0.0)\n",
    "    return batch_image,batch_label_on_hot,batch_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            self.X = tf.placeholder(tf.float32,[None,96,96,3])\n",
    "            X_img = self.X\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 500])\n",
    "\n",
    "            # Convolutional Layer #1 and Pooling Layer #1\n",
    "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout1 = tf.layers.dropout(inputs=pool1,\n",
    "                                         rate=0.7, training=self.training)\n",
    "            \n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout2 = tf.layers.dropout(inputs=pool2,\n",
    "                                         rate=0.7, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #3 and Pooling Layer #3\n",
    "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\n",
    "                                     padding=\"same\", activation=tf.nn.relu)\n",
    "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                                            padding=\"same\", strides=2)\n",
    "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
    "                                         rate=0.7, training=self.training)\n",
    "            \n",
    "            # Convolutional Layer #4 and Pooling Layer #4\n",
    "            conv4 = tf.layers.conv2d(inputs=dropout3, filters=256, kernel_size=[3, 3],\n",
    "                                     padding=\"same\", activation=tf.nn.relu)\n",
    "            pool4 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                                            padding=\"same\", strides=2)\n",
    "            dropout4 = tf.layers.dropout(inputs=pool3,\n",
    "                                         rate=0.7, training=self.training)\n",
    "\n",
    "            # Dense Layer with Relu\n",
    "            flat = tf.reshape(dropout4, [-1, 256 * 6 * 6])\n",
    "            dense5 = tf.layers.dense(inputs=flat,\n",
    "                                     units=9216, activation=tf.nn.relu)\n",
    "            dropout5 = tf.layers.dropout(inputs=dense5,\n",
    "                                         rate=0.5, training=self.training)\n",
    "\n",
    "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
    "            self.logits = tf.layers.dense(inputs=dropout5, units=500)\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, training=False):\n",
    "        return self.sess.run(self.logits,\n",
    "                             feed_dict={self.X: x_test, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy,\n",
    "                             feed_dict={self.X: x_test,\n",
    "                                        self.Y: y_test, self.training: training})\n",
    "\n",
    "    def train(self, x_data, y_data, training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.training: training})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started!\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Input to reshape is a tensor with 58437 values, but the requested shape has 27648\n",
      "\t [[Node: Reshape = Reshape[T=DT_UINT8, Tshape=DT_INT32, _class=[\"loc:@random_flip_left_right/Switch_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](DecodeJpeg, Reshape/shape)]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'learning_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f0de646a15f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"m1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d0e5bb4d3061>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess, name)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d0e5bb4d3061>\u001b[0m in \u001b[0;36m_build_net\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m             logits=self.logits, labels=self.Y))\n\u001b[1;32m     62\u001b[0m         self.optimizer = tf.train.AdamOptimizer(\n\u001b[0;32m---> 63\u001b[0;31m             learning_rate=learning_rate).minimize(self.cost)\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         correct_prediction = tf.equal(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learning_rate' is not defined"
     ]
    }
   ],
   "source": [
    "print('Learning Started!')\n",
    "image_batch,label_batch,file_batch = read_data_batch(TRAINING_FILE) \n",
    "\n",
    "validate_image_batch,validate_label_batch,validate_file_batch = read_data_batch(TEST_FILE)\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    #saver = tf.train.Saver() # create saver to store training model into file\n",
    "    init_op = tf.global_variables_initializer() # use this for tensorflow 0.12rc0\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    sess.run(init_op)\n",
    "    m1 = Model(sess,\"m1\")\n",
    "    for epoch in range(15):\n",
    "        avg_cost = 0\n",
    "        total_batch = 5\n",
    "\n",
    "        for i in range (total_batch):\n",
    "            images_,labels_ = sess.run([image_batch,label_batch])\n",
    "            c, _ = m1.train(images_, labels_)\n",
    "            avg_cost += c / total_batch\n",
    "        print(\"epoch = \" , epoch , \" cost = \" , avg_cost)\n",
    "    # validation steps\n",
    "    validate_images_,validate_labels_ = sess.run([validate_image_batch,validate_label_batch])\n",
    "    print(\"Accuracy = \" , m1.get_accuracy(validate_images_,validate_labels))\n",
    "    #saver.save(sess, 'face_recog') # save session\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
